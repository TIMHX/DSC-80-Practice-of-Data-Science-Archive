{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "sought-authority",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"lab.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aging-summit",
   "metadata": {},
   "source": [
    "# DSC 80: Lab 06\n",
    "\n",
    "### Due Date: Monday November 8th, 11:59 PM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continental-spell",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "Much like in DSC 10, this Jupyter Notebook contains the statements of the problems and provides code and markdown cells to display your answers to the problems. Unlike DSC 10, the notebook is *only* for displaying a readable version of your final answers. The coding work will be developed in an accompanying `lab*.py` file, that will be imported into the current notebook.\n",
    "\n",
    "Labs and programming assignments will be graded in (at most) two ways:\n",
    "1. The functions and classes in the accompanying python file will be tested (a la DSC 20),\n",
    "2. The notebook will be graded (for graphs and free response questions).\n",
    "\n",
    "**Do not change the function names in the `*.py` file**\n",
    "- The functions in the `*.py` file are how your assignment is graded, and they are graded by their name. The dictionary at the end of the file (`GRADED FUNCTIONS`) contains the \"grading list\". The final function in the file allows your doctests to check that all the necessary functions exist.\n",
    "- If you changed something you weren't supposed to, just use git to revert!\n",
    "\n",
    "**Tips for working in the Notebook**:\n",
    "- The notebooks serve to present you the questions and give you a place to present your results for later review.\n",
    "- The notebook on *lab assignments* are not graded (only the `.py` file).\n",
    "- Notebooks for PAs will serve as a final report for the assignment, and contain conclusions and answers to open ended questions that are graded.\n",
    "- The notebook serves as a nice environment for 'pre-development' and experimentation before designing your function in your `.py` file.\n",
    "\n",
    "**Tips for developing in the .py file**:\n",
    "- Do not change the function names in the starter code; grading is done using these function names.\n",
    "- Do not change the docstrings in the functions. These are there to tell you if your work is on the right track!\n",
    "- You are encouraged to write your own additional functions to solve the lab! \n",
    "    - Developing in python usually consists of larger files, with many short functions.\n",
    "    - You may write your other functions in an additional `.py` file that you import in `lab.py` (much like we do in the notebook).\n",
    "- Always document your code!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "designed-stylus",
   "metadata": {},
   "source": [
    "### Importing code from `lab.py`\n",
    "\n",
    "* We import our `.py` file that's contained in the same directory as this notebook.\n",
    "* We use the `autoreload` notebook extension to make changes to our `lab.py` file immediately available in our notebook. Without this extension, we would need to restart the notebook kernel to see any changes to `lab.py` in the notebook.\n",
    "    - `autoreload` is necessary because, upon import, `lab.py` is compiled to bytecode (in the directory `__pycache__`). Subsequent imports of `lab` merely import the existing compiled python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "democratic-favor",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "external-marsh",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lab import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cosmetic-newfoundland",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import time\n",
    "import requests\n",
    "import bs4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overall-domestic",
   "metadata": {},
   "source": [
    "# Basic HTML tags practice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporate-committee",
   "metadata": {},
   "source": [
    "**Question 1**\n",
    "\n",
    "Create a very basic `html` file that satisfies the following properties:\n",
    "\n",
    "1. Has `<head>` and `<body>` tags.\n",
    "2. Has a title\n",
    "3. Inside the body tags:\n",
    "    * At least two headers\n",
    "    * At least three images:\n",
    "        * At least one image must be a local file;\n",
    "        * At least one image must be linked to online source; \n",
    "        * At least one image has to have default text when it cannot be displayed.\n",
    "    * At least three references (hyperlinks) to different web pages;\n",
    "    * At least one table with two columns.\n",
    "    \n",
    "        \n",
    "   \n",
    "4. Save your work as `lab06_1.html` in the same directory as `lab.py`, make sure it loads in the browser and do not forget to submit it.\n",
    "5. **Do not forget to submit all data files needed to display your page.**\n",
    "\n",
    "**Note:** You can toy with (basic) HTML in the cells of a notebook, using either a \"markdown cell\" or by using the `IPython.display.HTML` function. However, be sure to open your saved file in a browser to be sure the page displays properly!\n",
    "\n",
    "**Note:** If you work within Jupyter Notebook, you can later copy your text into a text editor and save it with the .html extension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classical-cooperation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cordless-dallas",
   "metadata": {},
   "outputs": [],
   "source": [
    "question1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solved-reply",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "divided-apollo",
   "metadata": {},
   "source": [
    "# Scraping an Online Bookstore\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improving-logic",
   "metadata": {},
   "source": [
    "**Question 2**\n",
    "\n",
    "Browse through the following fake on-line bookstore: http://books.toscrape.com/. This website is meant for toying with scraping.\n",
    "\n",
    "Scrape the website, collecting data on all books that have **at least a four-star rating**, with a price **under £50** and belong to the book categories you want. You should collect the data in a dataframe as below (if you get an encoding error on your prices columns, like you see in the table below, don't worry about it):\n",
    "<img src=\"data/bookdata.png\">\n",
    "\n",
    "\n",
    "Do this using the following steps:\n",
    "1. Create a function `extract_book_links` that takes in the content of a book-listing page (a string of html), and returns a list of urls of book-detail pages that satisfy the requirements on \"*at least* a four-star rating, and prices are *under* £50\". \n",
    "\n",
    "2. Create a function `get_product_info` that takes in the content of a book-detail page (a string of html), a variable `categories` that is a list of book categories you want. If this input book is in the categories you want, returns a dictionary corresponding to a row in the dataframe in the image above (where the keys are the column names and the values are the row values); else, skip this book since this is not the book you want (ie. return None).\n",
    "\n",
    "3. Create a function `scrape_books` of a single variable `k` that scrapes the first `k` pages of the bookstore (as determined by starting at the url above and clicking on the 'next' button),a variable `categories` that is a list of book categories you want, and returns a dataframe of books as the picture above. (Note: make sure the books returned satisfy the requirements set in part 1 about rating and price).\n",
    "\n",
    "\n",
    "*Note:* Your function should take under 180 seconds to run through the entire bookstore.\n",
    "\n",
    "*Note:* Don't worry about type casting (ie changing number of reviews to an int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "collected-atlanta",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = os.path.join('data', 'products.html')\n",
    "text = open(fp, encoding='utf-8').read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "complicated-three",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['seven-brief-lessons-on-physics_219/index.html',\n",
       " 'scarlet-the-lunar-chronicles-2_218/index.html',\n",
       " 'saga-volume-3-saga-collected-editions-3_216/index.html',\n",
       " 'running-with-scissors_215/index.html',\n",
       " 'rise-of-the-rocket-girls-the-women-who-propelled-us-from-missiles-to-the-moon-to-mars_213/index.html',\n",
       " 'ready-player-one_209/index.html']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup = bs4.BeautifulSoup(text)\n",
    "cell = soup.find_all('article', {'class': 'product_pod'})\n",
    "result = []\n",
    "for book in cell:\n",
    "    price = book.find('p', {'class': 'price_color'}).text\n",
    "    rate = book.select('p[class*=\"star-rating \"]')[0].get('class')[1]\n",
    "    #title = book.find_all('a')[1].get('title')\n",
    "    if (float(price[1:]) < 50) and ((rate == 'Five')|(rate == 'Four')):\n",
    "        hrefs = book.find_all('a')\n",
    "        result.append(hrefs[0].get('href'))\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c8f4e7d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Availability': 'In stock (1 available)',\n",
       " 'Category': 'Default',\n",
       " 'Description': \"Mary Shelley began writing Frankenstein when she was only eighteen. At once a Gothic thriller, a passionate romance, and a cautionary tale about the dangers of science, Frankenstein tells the story of committed science student Victor Frankenstein. Obsessed with discovering the cause of generation and life and bestowing animation upon lifeless matter, Frankenstein assembles Mary Shelley began writing Frankenstein when she was only eighteen. At once a Gothic thriller, a passionate romance, and a cautionary tale about the dangers of science, Frankenstein tells the story of committed science student Victor Frankenstein. Obsessed with discovering the cause of generation and life and bestowing animation upon lifeless matter, Frankenstein assembles a human being from stolen body parts but; upon bringing it to life, he recoils in horror at the creature's hideousness. Tormented by isolation and loneliness, the once-innocent creature turns to evil and unleashes a campaign of murderous revenge against his creator, Frankenstein.Frankenstein, an instant bestseller and an important ancestor of both the horror and science fiction genres, not only tells a terrifying story, but also raises profound, disturbing questions about the very nature of life and the place of humankind within the cosmos: What does it mean to be human? What responsibilities do we have to each other? How far can we go in tampering with Nature? In our age, filled with news of organ donation genetic engineering, and bio-terrorism, these questions are more relevant than ever. ...more\",\n",
       " 'Number of reviews': '0',\n",
       " 'Price (excl. tax)': '£38.00',\n",
       " 'Price (incl. tax)': '£38.00',\n",
       " 'Product Type': 'Books',\n",
       " 'Rating': 'Two',\n",
       " 'Tax': '£0.00',\n",
       " 'Title': 'Frankenstein',\n",
       " 'UPC': 'a492f49a3e2b6a71'}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp = os.path.join('data', 'Frankenstein.html')\n",
    "out = get_product_info(open(fp, encoding='utf-8').read(), ['Default'])\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9cee9a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = os.path.join('data', 'Frankenstein.html')\n",
    "text = open(fp, encoding='utf-8').read()\n",
    "soup = bs4.BeautifulSoup(text, features=\"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "61526e16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Default'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.select('a[href*=\"/category/books/\"]')[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e103a112",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "34c1673b",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 1\n",
    "categories = ['Mystery']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "47be02c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Availability</th>\n",
       "      <th>Category</th>\n",
       "      <th>Description</th>\n",
       "      <th>Number of reviews</th>\n",
       "      <th>Price (excl. tax)</th>\n",
       "      <th>Price (incl. tax)</th>\n",
       "      <th>Product Type</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Tax</th>\n",
       "      <th>Title</th>\n",
       "      <th>UPC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In stock (20 available)</td>\n",
       "      <td>Mystery</td>\n",
       "      <td>WICKED above her hipbone, GIRL across her hear...</td>\n",
       "      <td>0</td>\n",
       "      <td>Â£47.82</td>\n",
       "      <td>Â£47.82</td>\n",
       "      <td>Books</td>\n",
       "      <td>Four</td>\n",
       "      <td>Â£0.00</td>\n",
       "      <td>Sharp Objects</td>\n",
       "      <td>e00eb4fd7b871a48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Availability Category  \\\n",
       "0  In stock (20 available)  Mystery   \n",
       "\n",
       "                                         Description Number of reviews  \\\n",
       "0  WICKED above her hipbone, GIRL across her hear...                 0   \n",
       "\n",
       "  Price (excl. tax) Price (incl. tax) Product Type Rating     Tax  \\\n",
       "0           Â£47.82           Â£47.82        Books   Four  Â£0.00   \n",
       "\n",
       "           Title               UPC  \n",
       "0  Sharp Objects  e00eb4fd7b871a48  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scrape_books(k, categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "24df77c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Availability</th>\n",
       "      <th>Category</th>\n",
       "      <th>Description</th>\n",
       "      <th>Number of reviews</th>\n",
       "      <th>Price (excl. tax)</th>\n",
       "      <th>Price (incl. tax)</th>\n",
       "      <th>Product Type</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Tax</th>\n",
       "      <th>Title</th>\n",
       "      <th>UPC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In stock (20 available)</td>\n",
       "      <td>Mystery</td>\n",
       "      <td>WICKED above her hipbone, GIRL across her hear...</td>\n",
       "      <td>0</td>\n",
       "      <td>Â£47.82</td>\n",
       "      <td>Â£47.82</td>\n",
       "      <td>Books</td>\n",
       "      <td>Four</td>\n",
       "      <td>Â£0.00</td>\n",
       "      <td>Sharp Objects</td>\n",
       "      <td>e00eb4fd7b871a48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Availability Category  \\\n",
       "0  In stock (20 available)  Mystery   \n",
       "\n",
       "                                         Description Number of reviews  \\\n",
       "0  WICKED above her hipbone, GIRL across her hear...                 0   \n",
       "\n",
       "  Price (excl. tax) Price (incl. tax) Product Type Rating     Tax  \\\n",
       "0           Â£47.82           Â£47.82        Books   Four  Â£0.00   \n",
       "\n",
       "           Title               UPC  \n",
       "0  Sharp Objects  e00eb4fd7b871a48  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages = [f'http://books.toscrape.com/catalogue/page-{num}.html' for num in range(1,k+1)]\n",
    "book_list = []\n",
    "book_dict = []\n",
    "for page in pages:\n",
    "    page_request = requests.get(page)\n",
    "    book_list.extend(extract_book_links(page_request.text))\n",
    "for book in book_list:\n",
    "    book_request = requests.get('http://books.toscrape.com/catalogue/' + book)\n",
    "    book_info = get_product_info(book_request.text,categories)\n",
    "    if book_info is not None:\n",
    "        book_dict.append(book_info)\n",
    "pd.DataFrame(book_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "crazy-working",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q2</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q2 results: All test cases passed!"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "magnetic-holiday",
   "metadata": {},
   "source": [
    "# API Requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "normal-serbia",
   "metadata": {},
   "source": [
    "**Question 3**\n",
    "\n",
    "You trade stocks as a hobby. As an avid pandas coder, you figured it is best to calculate some statistics by pulling data from a public API (https://financialmodelingprep.com/developer/docs/#Stock-Historical-Price). Specifically, \"Historical price with change and volume interval\".\n",
    "\n",
    "Some definitions (these are the ones you need to know):\n",
    "- open: The opening price of a stock at the beginning of a trading day\n",
    "- close: The closing price of a stock at the end of a trading day\n",
    "- volume: The total number of shares being traded in a day\n",
    "- percent change: difference in price with respect to the original price (in percentages)\n",
    "\n",
    "\n",
    "1. Create a function `stock_history` which takes in the stock code (`ticker`) as a string, `year` and `month` as integers, and return a dataframe which has the price history for that stock in that month (include all columns).\n",
    "\n",
    "2. Create a function `stock_stats` that takes in the output dataframe from `stock_history` and output the stock price change as a percentage and a rough total transaction volume **in billion dollars** for that month. Assume that on average, shares are traded at the midpoint price of high and low for that day. Return these two values as a tuple in a readable format: reserve 2 decimal points for both values and add a plus or minus sign at the front of the percent change. \n",
    "$$ \\text{Total Transaction Volume (in dollars)} = \\text{Volume (number of shares traded)} \\times \\text{Price} $$\n",
    "\n",
    "*Example*: If \\\\$BYND opens at \\\\$80 and closes at \\\\$120 with a volume of 1 million, its percent change for the day is $(\\$120-\\$80) \\div \\$80 = +50.00\\%$. And the estimated total transaction volume is: $(\\$80+\\$120) / 2 \\times 10^6 = 0.10\\text{B}$.\n",
    "\n",
    "\n",
    "Hint: [pd.date_range](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.date_range.html), \n",
    "\n",
    "*Note:* Make sure you read the API documentation if you get stuck!\n",
    "\n",
    "*Note 2:* In order to make successful requests, you will need an API key. In order to get one, you will need to sign up to the website. Once signed up, you can use the API key that comes with the free plan. It has a limit of 250 requests per day, which should be more than enough. In the code below, replace `your_key` when making requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "415e3652",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker = 'BYND'\n",
    "year = 2019\n",
    "month = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "rapid-fossil",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://financialmodelingprep.com/api/v3/historical-price-full/{t}?apikey=a2311ec4aaf814e3bb089cd297376cff'.format(t = ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "b3581389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('+54.29%', '33.64B')"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = history.copy()\n",
    "df = df.sort_values('date').reset_index()\n",
    "op = df.iloc[0].open\n",
    "cl = df.iloc[-1].close\n",
    "hi = max(df['high'])\n",
    "lo = min(df['low'])\n",
    "volume = sum(df['volume'])\n",
    "PC = str(round((cl - op)/op*100, 2))+'%'\n",
    "if not PC.startswith('-'):\n",
    "    PC = '+' + PC\n",
    "TTV = str(round(sum((history['low'] + history['high'])/2 * history['volume']/(10**9)), 2))+'B'\n",
    "(PC, TTV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "8925d5f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(104.139999, 160.679993)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op = history.iloc[-1].open\n",
    "cl = history.iloc[0].close\n",
    "(op,cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "6fe01d25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'54.29%'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PC = str(round((cl - op) / op * 100, 2)) + '%'\n",
    "PC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "charming-opera",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adjClose</th>\n",
       "      <th>volume</th>\n",
       "      <th>unadjustedVolume</th>\n",
       "      <th>change</th>\n",
       "      <th>changePercent</th>\n",
       "      <th>vwap</th>\n",
       "      <th>label</th>\n",
       "      <th>changeOverTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>2019-06-03</td>\n",
       "      <td>104.139999</td>\n",
       "      <td>108.669998</td>\n",
       "      <td>95.662003</td>\n",
       "      <td>96.160004</td>\n",
       "      <td>96.160004</td>\n",
       "      <td>8027700.0</td>\n",
       "      <td>8027700.0</td>\n",
       "      <td>-7.98000</td>\n",
       "      <td>-7.663</td>\n",
       "      <td>100.16400</td>\n",
       "      <td>June 03, 19</td>\n",
       "      <td>-0.07663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>2019-06-04</td>\n",
       "      <td>101.250000</td>\n",
       "      <td>103.500000</td>\n",
       "      <td>97.820000</td>\n",
       "      <td>103.410004</td>\n",
       "      <td>103.410004</td>\n",
       "      <td>5484900.0</td>\n",
       "      <td>5484900.0</td>\n",
       "      <td>2.16000</td>\n",
       "      <td>2.133</td>\n",
       "      <td>101.57667</td>\n",
       "      <td>June 04, 19</td>\n",
       "      <td>0.02133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "      <td>2019-06-05</td>\n",
       "      <td>105.500000</td>\n",
       "      <td>105.500000</td>\n",
       "      <td>99.639999</td>\n",
       "      <td>102.599998</td>\n",
       "      <td>102.599998</td>\n",
       "      <td>4283500.0</td>\n",
       "      <td>4283500.0</td>\n",
       "      <td>-2.90000</td>\n",
       "      <td>-2.749</td>\n",
       "      <td>102.58000</td>\n",
       "      <td>June 05, 19</td>\n",
       "      <td>-0.02749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>2019-06-06</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>102.250000</td>\n",
       "      <td>98.849998</td>\n",
       "      <td>99.500000</td>\n",
       "      <td>99.500000</td>\n",
       "      <td>6484000.0</td>\n",
       "      <td>6484000.0</td>\n",
       "      <td>-2.50000</td>\n",
       "      <td>-2.451</td>\n",
       "      <td>100.20000</td>\n",
       "      <td>June 06, 19</td>\n",
       "      <td>-0.02451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>2019-06-07</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>149.460007</td>\n",
       "      <td>120.760002</td>\n",
       "      <td>138.649994</td>\n",
       "      <td>138.649994</td>\n",
       "      <td>23916700.0</td>\n",
       "      <td>23916700.0</td>\n",
       "      <td>8.64999</td>\n",
       "      <td>6.654</td>\n",
       "      <td>136.29000</td>\n",
       "      <td>June 07, 19</td>\n",
       "      <td>0.06654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14</td>\n",
       "      <td>2019-06-10</td>\n",
       "      <td>155.699997</td>\n",
       "      <td>186.429993</td>\n",
       "      <td>147.000000</td>\n",
       "      <td>168.100006</td>\n",
       "      <td>168.100006</td>\n",
       "      <td>24986000.0</td>\n",
       "      <td>24986000.0</td>\n",
       "      <td>12.40001</td>\n",
       "      <td>7.964</td>\n",
       "      <td>167.17667</td>\n",
       "      <td>June 10, 19</td>\n",
       "      <td>0.07964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13</td>\n",
       "      <td>2019-06-11</td>\n",
       "      <td>145.250000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>125.230003</td>\n",
       "      <td>126.040001</td>\n",
       "      <td>126.040001</td>\n",
       "      <td>15516000.0</td>\n",
       "      <td>15516000.0</td>\n",
       "      <td>-19.21000</td>\n",
       "      <td>-13.225</td>\n",
       "      <td>133.75667</td>\n",
       "      <td>June 11, 19</td>\n",
       "      <td>-0.13225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12</td>\n",
       "      <td>2019-06-12</td>\n",
       "      <td>133.990005</td>\n",
       "      <td>150.449997</td>\n",
       "      <td>131.563004</td>\n",
       "      <td>141.970001</td>\n",
       "      <td>141.970001</td>\n",
       "      <td>16918600.0</td>\n",
       "      <td>16918600.0</td>\n",
       "      <td>7.98000</td>\n",
       "      <td>5.956</td>\n",
       "      <td>141.32767</td>\n",
       "      <td>June 12, 19</td>\n",
       "      <td>0.05956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11</td>\n",
       "      <td>2019-06-13</td>\n",
       "      <td>141.520004</td>\n",
       "      <td>146.449997</td>\n",
       "      <td>134.250000</td>\n",
       "      <td>141.389999</td>\n",
       "      <td>141.389999</td>\n",
       "      <td>9474600.0</td>\n",
       "      <td>9474600.0</td>\n",
       "      <td>-0.13001</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>140.69667</td>\n",
       "      <td>June 13, 19</td>\n",
       "      <td>-0.00092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>2019-06-14</td>\n",
       "      <td>142.009995</td>\n",
       "      <td>157.899994</td>\n",
       "      <td>141.800003</td>\n",
       "      <td>151.479996</td>\n",
       "      <td>151.479996</td>\n",
       "      <td>14964600.0</td>\n",
       "      <td>14964600.0</td>\n",
       "      <td>9.47000</td>\n",
       "      <td>6.669</td>\n",
       "      <td>150.39333</td>\n",
       "      <td>June 14, 19</td>\n",
       "      <td>0.06669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9</td>\n",
       "      <td>2019-06-17</td>\n",
       "      <td>163.179993</td>\n",
       "      <td>171.190002</td>\n",
       "      <td>160.610992</td>\n",
       "      <td>169.960007</td>\n",
       "      <td>169.960007</td>\n",
       "      <td>14626700.0</td>\n",
       "      <td>14626700.0</td>\n",
       "      <td>6.78001</td>\n",
       "      <td>4.155</td>\n",
       "      <td>167.25367</td>\n",
       "      <td>June 17, 19</td>\n",
       "      <td>0.04155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8</td>\n",
       "      <td>2019-06-18</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>201.880005</td>\n",
       "      <td>160.699997</td>\n",
       "      <td>169.889999</td>\n",
       "      <td>169.889999</td>\n",
       "      <td>23966900.0</td>\n",
       "      <td>23966900.0</td>\n",
       "      <td>-30.11000</td>\n",
       "      <td>-15.055</td>\n",
       "      <td>177.49000</td>\n",
       "      <td>June 18, 19</td>\n",
       "      <td>-0.15055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7</td>\n",
       "      <td>2019-06-19</td>\n",
       "      <td>171.369995</td>\n",
       "      <td>174.449997</td>\n",
       "      <td>162.250000</td>\n",
       "      <td>169.279999</td>\n",
       "      <td>169.279999</td>\n",
       "      <td>9452000.0</td>\n",
       "      <td>9452000.0</td>\n",
       "      <td>-2.09000</td>\n",
       "      <td>-1.220</td>\n",
       "      <td>168.66000</td>\n",
       "      <td>June 19, 19</td>\n",
       "      <td>-0.01220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6</td>\n",
       "      <td>2019-06-20</td>\n",
       "      <td>173.000000</td>\n",
       "      <td>174.000000</td>\n",
       "      <td>163.300003</td>\n",
       "      <td>165.169998</td>\n",
       "      <td>165.169998</td>\n",
       "      <td>6660500.0</td>\n",
       "      <td>6660500.0</td>\n",
       "      <td>-7.83000</td>\n",
       "      <td>-4.526</td>\n",
       "      <td>167.49000</td>\n",
       "      <td>June 20, 19</td>\n",
       "      <td>-0.04526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5</td>\n",
       "      <td>2019-06-21</td>\n",
       "      <td>153.539993</td>\n",
       "      <td>161.789993</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>154.130005</td>\n",
       "      <td>154.130005</td>\n",
       "      <td>7474600.0</td>\n",
       "      <td>7474600.0</td>\n",
       "      <td>0.59001</td>\n",
       "      <td>0.384</td>\n",
       "      <td>155.30667</td>\n",
       "      <td>June 21, 19</td>\n",
       "      <td>0.00384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4</td>\n",
       "      <td>2019-06-24</td>\n",
       "      <td>151.880005</td>\n",
       "      <td>152.699997</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>140.990005</td>\n",
       "      <td>140.990005</td>\n",
       "      <td>6538500.0</td>\n",
       "      <td>6538500.0</td>\n",
       "      <td>-10.89000</td>\n",
       "      <td>-7.170</td>\n",
       "      <td>143.89667</td>\n",
       "      <td>June 24, 19</td>\n",
       "      <td>-0.07170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3</td>\n",
       "      <td>2019-06-25</td>\n",
       "      <td>138.500000</td>\n",
       "      <td>150.690002</td>\n",
       "      <td>138.343002</td>\n",
       "      <td>150.600006</td>\n",
       "      <td>150.600006</td>\n",
       "      <td>6632500.0</td>\n",
       "      <td>6632500.0</td>\n",
       "      <td>12.10001</td>\n",
       "      <td>8.736</td>\n",
       "      <td>146.54434</td>\n",
       "      <td>June 25, 19</td>\n",
       "      <td>0.08736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-06-26</td>\n",
       "      <td>160.100006</td>\n",
       "      <td>162.250000</td>\n",
       "      <td>153.020004</td>\n",
       "      <td>160.479996</td>\n",
       "      <td>160.479996</td>\n",
       "      <td>6378600.0</td>\n",
       "      <td>6378600.0</td>\n",
       "      <td>0.37999</td>\n",
       "      <td>0.237</td>\n",
       "      <td>158.58333</td>\n",
       "      <td>June 26, 19</td>\n",
       "      <td>0.00237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-06-27</td>\n",
       "      <td>157.309998</td>\n",
       "      <td>164.789993</td>\n",
       "      <td>155.449997</td>\n",
       "      <td>162.910004</td>\n",
       "      <td>162.910004</td>\n",
       "      <td>5731400.0</td>\n",
       "      <td>5731400.0</td>\n",
       "      <td>5.60001</td>\n",
       "      <td>3.560</td>\n",
       "      <td>161.05000</td>\n",
       "      <td>June 27, 19</td>\n",
       "      <td>0.03560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-06-28</td>\n",
       "      <td>165.300003</td>\n",
       "      <td>168.800003</td>\n",
       "      <td>159.550003</td>\n",
       "      <td>160.679993</td>\n",
       "      <td>160.679993</td>\n",
       "      <td>7315300.0</td>\n",
       "      <td>7315300.0</td>\n",
       "      <td>-4.62001</td>\n",
       "      <td>-2.795</td>\n",
       "      <td>163.01000</td>\n",
       "      <td>June 28, 19</td>\n",
       "      <td>-0.02795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index       date        open        high         low       close  \\\n",
       "0      19 2019-06-03  104.139999  108.669998   95.662003   96.160004   \n",
       "1      18 2019-06-04  101.250000  103.500000   97.820000  103.410004   \n",
       "2      17 2019-06-05  105.500000  105.500000   99.639999  102.599998   \n",
       "3      16 2019-06-06  102.000000  102.250000   98.849998   99.500000   \n",
       "4      15 2019-06-07  130.000000  149.460007  120.760002  138.649994   \n",
       "5      14 2019-06-10  155.699997  186.429993  147.000000  168.100006   \n",
       "6      13 2019-06-11  145.250000  150.000000  125.230003  126.040001   \n",
       "7      12 2019-06-12  133.990005  150.449997  131.563004  141.970001   \n",
       "8      11 2019-06-13  141.520004  146.449997  134.250000  141.389999   \n",
       "9      10 2019-06-14  142.009995  157.899994  141.800003  151.479996   \n",
       "10      9 2019-06-17  163.179993  171.190002  160.610992  169.960007   \n",
       "11      8 2019-06-18  200.000000  201.880005  160.699997  169.889999   \n",
       "12      7 2019-06-19  171.369995  174.449997  162.250000  169.279999   \n",
       "13      6 2019-06-20  173.000000  174.000000  163.300003  165.169998   \n",
       "14      5 2019-06-21  153.539993  161.789993  150.000000  154.130005   \n",
       "15      4 2019-06-24  151.880005  152.699997  138.000000  140.990005   \n",
       "16      3 2019-06-25  138.500000  150.690002  138.343002  150.600006   \n",
       "17      2 2019-06-26  160.100006  162.250000  153.020004  160.479996   \n",
       "18      1 2019-06-27  157.309998  164.789993  155.449997  162.910004   \n",
       "19      0 2019-06-28  165.300003  168.800003  159.550003  160.679993   \n",
       "\n",
       "      adjClose      volume  unadjustedVolume    change  changePercent  \\\n",
       "0    96.160004   8027700.0         8027700.0  -7.98000         -7.663   \n",
       "1   103.410004   5484900.0         5484900.0   2.16000          2.133   \n",
       "2   102.599998   4283500.0         4283500.0  -2.90000         -2.749   \n",
       "3    99.500000   6484000.0         6484000.0  -2.50000         -2.451   \n",
       "4   138.649994  23916700.0        23916700.0   8.64999          6.654   \n",
       "5   168.100006  24986000.0        24986000.0  12.40001          7.964   \n",
       "6   126.040001  15516000.0        15516000.0 -19.21000        -13.225   \n",
       "7   141.970001  16918600.0        16918600.0   7.98000          5.956   \n",
       "8   141.389999   9474600.0         9474600.0  -0.13001         -0.092   \n",
       "9   151.479996  14964600.0        14964600.0   9.47000          6.669   \n",
       "10  169.960007  14626700.0        14626700.0   6.78001          4.155   \n",
       "11  169.889999  23966900.0        23966900.0 -30.11000        -15.055   \n",
       "12  169.279999   9452000.0         9452000.0  -2.09000         -1.220   \n",
       "13  165.169998   6660500.0         6660500.0  -7.83000         -4.526   \n",
       "14  154.130005   7474600.0         7474600.0   0.59001          0.384   \n",
       "15  140.990005   6538500.0         6538500.0 -10.89000         -7.170   \n",
       "16  150.600006   6632500.0         6632500.0  12.10001          8.736   \n",
       "17  160.479996   6378600.0         6378600.0   0.37999          0.237   \n",
       "18  162.910004   5731400.0         5731400.0   5.60001          3.560   \n",
       "19  160.679993   7315300.0         7315300.0  -4.62001         -2.795   \n",
       "\n",
       "         vwap        label  changeOverTime  \n",
       "0   100.16400  June 03, 19        -0.07663  \n",
       "1   101.57667  June 04, 19         0.02133  \n",
       "2   102.58000  June 05, 19        -0.02749  \n",
       "3   100.20000  June 06, 19        -0.02451  \n",
       "4   136.29000  June 07, 19         0.06654  \n",
       "5   167.17667  June 10, 19         0.07964  \n",
       "6   133.75667  June 11, 19        -0.13225  \n",
       "7   141.32767  June 12, 19         0.05956  \n",
       "8   140.69667  June 13, 19        -0.00092  \n",
       "9   150.39333  June 14, 19         0.06669  \n",
       "10  167.25367  June 17, 19         0.04155  \n",
       "11  177.49000  June 18, 19        -0.15055  \n",
       "12  168.66000  June 19, 19        -0.01220  \n",
       "13  167.49000  June 20, 19        -0.04526  \n",
       "14  155.30667  June 21, 19         0.00384  \n",
       "15  143.89667  June 24, 19        -0.07170  \n",
       "16  146.54434  June 25, 19         0.08736  \n",
       "17  158.58333  June 26, 19         0.00237  \n",
       "18  161.05000  June 27, 19         0.03560  \n",
       "19  163.01000  June 28, 19        -0.02795  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = stock_history('BYND', 2019, 6)\n",
    "history.sort_values('date').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "040941f2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('+54.29%', '33.64B')"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_stats(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "overhead-opposition",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q3</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q3 results: All test cases passed!"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pointed-chase",
   "metadata": {},
   "source": [
    "# Comment Threads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protective-childhood",
   "metadata": {},
   "source": [
    "**Question 4**\n",
    "\n",
    "As a hacker, you get your daily dose of tech news on [Hacker News](https://news.ycombinator.com/). The problem now is that you don't have internet access on your phone in your morning commute to work, so you want to save the interesting stories' comments thread beforehand in a flat file source like csv. You find their API documentation ( https://github.com/HackerNews/API) and implement the following task:\n",
    "\n",
    "1. Write a function `get_comments` that takes `storyid` as a parameter and returns a dataframe of all the comments below the news story. You can ignore 'dead' comments (you will know it when you see it). **Make sure the order of the comments in your dataframe is from top to bottom just as you see on the website**. You are allowed to use loops in this function. Addtional requirement: write at least one helper method\n",
    "\n",
    "You only want these information for the comments:\n",
    "1. `id`: the unique ids\n",
    "2. `by`: the author of the comment\n",
    "3. `parent`: who (also in unique ids) they are replying to\n",
    "4. `text`: the actual comment\n",
    "5. `time`: when the comment is created (in `pd.datetime` format)\n",
    "\n",
    "Hints:\n",
    "1. Use depth-first-search when traversing the comments tree.\n",
    "2. https://docs.python.org/3/tutorial/datastructures.html#using-lists-as-stacks.\n",
    "3. Check the size of your dataframe to the story's `descendants` attribute (number of comments).\n",
    "\n",
    "`news_endpoint = \"https://hacker-news.firebaseio.com/v0/item/{}.json\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "representative-distribution",
   "metadata": {},
   "outputs": [],
   "source": [
    "storyid = 18344932"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b2b25c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "by                                                  valyala\n",
       "id                                                 18380397\n",
       "parent                                             18344932\n",
       "text      TimescaleDB is great for storing time series c...\n",
       "time                                             1541400799\n",
       "type                                                comment\n",
       "dtype: object"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root = 'https://hacker-news.firebaseio.com/v0/item/18380397.json?print=pretty'\n",
    "pd.read_json(root, typ = 'series')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "computational-samba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "by                                                ScottWRobinson\n",
       "descendants                                                   18\n",
       "id                                                      18344932\n",
       "kids           [18380397, 18346406, 18348601, 18346750, 18346...\n",
       "score                                                         47\n",
       "time                                                  1540987334\n",
       "title                        TimescaleDB 1.0 Is Production Ready\n",
       "type                                                       story\n",
       "url            https://blog.timescale.com/1-0-enterprise-prod...\n",
       "dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root = \"https://hacker-news.firebaseio.com/v0/item/{}.json?print=pretty\".format(storyid)\n",
    "pd.read_json(root, typ = 'series')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e7db0d54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "fe6fbdb7",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-96-b7ae86784165>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-96-b7ae86784165>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    def walk(tree_path, global out):\u001b[0m\n\u001b[1;37m                        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "out = []\n",
    "def walk(tree_path, out):\n",
    "    tree = pd.read_json(tree_path, typ = 'series')\n",
    "    if 'kids' not in tree.index:\n",
    "        return tree\n",
    "    id_list = tree['kids']\n",
    "    for i in id_list:\n",
    "        path =  \"https://hacker-news.firebaseio.com/v0/item/{}.json?print=pretty\".format(i)\n",
    "        out.append(pd.read_json(path, typ = 'series'))\n",
    "        walk(path, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6a1357a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "by                                                  valyala\n",
       "id                                                 18380397\n",
       "parent                                             18344932\n",
       "text      TimescaleDB is great for storing time series c...\n",
       "time                                             1541400799\n",
       "type                                                comment\n",
       "dtype: object"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "walk(root, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "01e156e7",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'(0    4\n1    4\n2    4\nName: A, dtype: int64,)' is an invalid key",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-119-f5aa0f2bf09d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m9\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'A'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'B'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'A'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3022\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3023\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3024\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3025\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3026\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3078\u001b[0m             \u001b[0mcasted_key\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3079\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3080\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3082\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '(0    4\n1    4\n2    4\nName: A, dtype: int64,)' is an invalid key"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame([[4, 9]] * 3, columns=['A', 'B'])\n",
    "d.apply(np.sqrt)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "ab949ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Workspace\\DSC 80\\lab\\06-http\\assignment\\lab.py:237: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>by</th>\n",
       "      <th>parent</th>\n",
       "      <th>text</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18380397</td>\n",
       "      <td>valyala</td>\n",
       "      <td>18344932</td>\n",
       "      <td>TimescaleDB is great for storing time series c...</td>\n",
       "      <td>2018-11-05 06:53:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18346406</td>\n",
       "      <td>msiggy</td>\n",
       "      <td>18344932</td>\n",
       "      <td>I&amp;#x27;m excited to give this database a try i...</td>\n",
       "      <td>2018-10-31 15:20:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18348601</td>\n",
       "      <td>sman393</td>\n",
       "      <td>18344932</td>\n",
       "      <td>Can this be used side by side on normal Postgr...</td>\n",
       "      <td>2018-10-31 19:29:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18348631</td>\n",
       "      <td>RobAtticus</td>\n",
       "      <td>18348601</td>\n",
       "      <td>Yep, absolutely. Regular PostgreSQL tables coe...</td>\n",
       "      <td>2018-10-31 19:34:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18348984</td>\n",
       "      <td>sman393</td>\n",
       "      <td>18348631</td>\n",
       "      <td>Good to hear! how does the current TimescaleDB...</td>\n",
       "      <td>2018-10-31 20:23:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>18349540</td>\n",
       "      <td>RobAtticus</td>\n",
       "      <td>18348984</td>\n",
       "      <td>Not sure I follow exactly what you&amp;#x27;re ask...</td>\n",
       "      <td>2018-10-31 21:47:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>18350673</td>\n",
       "      <td>sman393</td>\n",
       "      <td>18349540</td>\n",
       "      <td>Alright thanks! I thought I read that Timescal...</td>\n",
       "      <td>2018-11-01 01:11:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>18351061</td>\n",
       "      <td>RobAtticus</td>\n",
       "      <td>18350673</td>\n",
       "      <td>It does not support sharding writes across mul...</td>\n",
       "      <td>2018-11-01 02:35:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>18346750</td>\n",
       "      <td>zip1234</td>\n",
       "      <td>18344932</td>\n",
       "      <td>How fast is it when it has a TB of data? I rea...</td>\n",
       "      <td>2018-10-31 15:51:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>18347260</td>\n",
       "      <td>nevi-me</td>\n",
       "      <td>18346750</td>\n",
       "      <td>I spent about 8 months writing data to TSDB. I...</td>\n",
       "      <td>2018-10-31 16:47:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>18347555</td>\n",
       "      <td>dominotw</td>\n",
       "      <td>18346750</td>\n",
       "      <td>They have some numbers on their blog. Its very...</td>\n",
       "      <td>2018-10-31 17:19:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>18346476</td>\n",
       "      <td>dominotw</td>\n",
       "      <td>18344932</td>\n",
       "      <td>I evaluated this heavily but had to backoff be...</td>\n",
       "      <td>2018-10-31 15:27:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>18346702</td>\n",
       "      <td>RobAtticus</td>\n",
       "      <td>18346476</td>\n",
       "      <td>Sorry to hear, though I&amp;#x27;d like to mention...</td>\n",
       "      <td>2018-10-31 15:47:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>18347232</td>\n",
       "      <td>grumpydba</td>\n",
       "      <td>18346702</td>\n",
       "      <td>Hi,&lt;p&gt;are the upcoming clustering efforts deve...</td>\n",
       "      <td>2018-10-31 16:44:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>18349689</td>\n",
       "      <td>jason_slack</td>\n",
       "      <td>18346476</td>\n",
       "      <td>What were the specs of the machine you were us...</td>\n",
       "      <td>2018-10-31 22:16:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>18346746</td>\n",
       "      <td>athenot</td>\n",
       "      <td>18344932</td>\n",
       "      <td>It would be nice if they did a quick compariso...</td>\n",
       "      <td>2018-10-31 15:51:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>18346787</td>\n",
       "      <td>RobAtticus</td>\n",
       "      <td>18346746</td>\n",
       "      <td>We do have comparisons, but judging by their M...</td>\n",
       "      <td>2018-10-31 15:56:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18346822</td>\n",
       "      <td>athenot</td>\n",
       "      <td>18346787</td>\n",
       "      <td>Thanks a lot, this is useful for comparing.&lt;p&gt;...</td>\n",
       "      <td>2018-10-31 16:00:29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id           by    parent  \\\n",
       "0   18380397      valyala  18344932   \n",
       "1   18346406       msiggy  18344932   \n",
       "2   18348601      sman393  18344932   \n",
       "3   18348631   RobAtticus  18348601   \n",
       "4   18348984      sman393  18348631   \n",
       "5   18349540   RobAtticus  18348984   \n",
       "6   18350673      sman393  18349540   \n",
       "7   18351061   RobAtticus  18350673   \n",
       "8   18346750      zip1234  18344932   \n",
       "9   18347260      nevi-me  18346750   \n",
       "10  18347555     dominotw  18346750   \n",
       "11  18346476     dominotw  18344932   \n",
       "12  18346702   RobAtticus  18346476   \n",
       "13  18347232    grumpydba  18346702   \n",
       "14  18349689  jason_slack  18346476   \n",
       "15  18346746      athenot  18344932   \n",
       "16  18346787   RobAtticus  18346746   \n",
       "17  18346822      athenot  18346787   \n",
       "\n",
       "                                                 text                time  \n",
       "0   TimescaleDB is great for storing time series c... 2018-11-05 06:53:19  \n",
       "1   I&#x27;m excited to give this database a try i... 2018-10-31 15:20:22  \n",
       "2   Can this be used side by side on normal Postgr... 2018-10-31 19:29:39  \n",
       "3   Yep, absolutely. Regular PostgreSQL tables coe... 2018-10-31 19:34:52  \n",
       "4   Good to hear! how does the current TimescaleDB... 2018-10-31 20:23:46  \n",
       "5   Not sure I follow exactly what you&#x27;re ask... 2018-10-31 21:47:20  \n",
       "6   Alright thanks! I thought I read that Timescal... 2018-11-01 01:11:59  \n",
       "7   It does not support sharding writes across mul... 2018-11-01 02:35:03  \n",
       "8   How fast is it when it has a TB of data? I rea... 2018-10-31 15:51:43  \n",
       "9   I spent about 8 months writing data to TSDB. I... 2018-10-31 16:47:34  \n",
       "10  They have some numbers on their blog. Its very... 2018-10-31 17:19:34  \n",
       "11  I evaluated this heavily but had to backoff be... 2018-10-31 15:27:29  \n",
       "12  Sorry to hear, though I&#x27;d like to mention... 2018-10-31 15:47:41  \n",
       "13  Hi,<p>are the upcoming clustering efforts deve... 2018-10-31 16:44:39  \n",
       "14  What were the specs of the machine you were us... 2018-10-31 22:16:27  \n",
       "15  It would be nice if they did a quick compariso... 2018-10-31 15:51:13  \n",
       "16  We do have comparisons, but judging by their M... 2018-10-31 15:56:39  \n",
       "17  Thanks a lot, this is useful for comparing.<p>... 2018-10-31 16:00:29  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_comments('18344932')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "essential-stupid",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q4</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q4 results: All test cases passed!"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alert-bibliography",
   "metadata": {},
   "source": [
    "## Congratulations! You're done!\n",
    "\n",
    "* Submit the lab on Gradescope"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dutch-cannon",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aquatic-helping",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "otter": {
   "tests": {
    "q1": {
     "name": "q1",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> import doctest\n>>> doctest.run_docstring_examples(question1, {'question1': question1, 'os': os})\n",
         "hidden": false,
         "locked": false,
         "points": 0
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2": {
     "name": "q2",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> import doctest\n>>> doctest.run_docstring_examples(extract_book_links, {'extract_book_links': extract_book_links, 'os': os})\n>>> doctest.run_docstring_examples(scrape_books, {'scrape_books': scrape_books, 'os': os})\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3": {
     "name": "q3",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> import doctest\n>>> doctest.run_docstring_examples(stock_history, {'stock_history': stock_history})\n>>> doctest.run_docstring_examples(stock_stats, {'stock_stats': stock_stats, 'stock_history': stock_history})\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4": {
     "name": "q4",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> import doctest\n>>> doctest.run_docstring_examples(get_comments, {'get_comments': get_comments})\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
