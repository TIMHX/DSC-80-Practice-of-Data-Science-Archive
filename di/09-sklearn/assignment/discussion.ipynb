{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"discussion.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion 9\n",
    "\n",
    "### Due Saturday November 20th, 11:59:59PM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-Learn: Transformers, Estimators, and Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from discussion import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformers and Estimators\n",
    "\n",
    "Scikit learn includes two *base* modeling classes: Transfomers and Estimators. Both are classes that are meant to be *fit* on (training) data and then later used to transform (or predict with) unseen data.\n",
    "\n",
    "### Transformers\n",
    "\n",
    "* Transformers take input data and transform it into output data via the `transform` method.\n",
    "* Sometimes transformers need prior information (parameters) about the data before transforming it.\n",
    "    - In this case, the transformer is *fit* using the `fit` method on training data to estimate the parameters.\n",
    "    - Once fit, the transformer may then be applied to `test` data (or unseen, new data).\n",
    "* Fit parameters are accessed via an instance variable that ends in an *underscore*.\n",
    "\n",
    "**Question 1** Using `Binarizer`, transform the `city-mpg` and `highway-mpg` column to 0 if the mpg is less than or equal to 25 and 1 if it's greater than 25."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>make</th>\n",
       "      <th>fuel-type</th>\n",
       "      <th>aspiration</th>\n",
       "      <th>num-of-doors</th>\n",
       "      <th>body-style</th>\n",
       "      <th>drive-wheels</th>\n",
       "      <th>engine-location</th>\n",
       "      <th>wheel-base</th>\n",
       "      <th>length</th>\n",
       "      <th>width</th>\n",
       "      <th>...</th>\n",
       "      <th>engine-size</th>\n",
       "      <th>fuel-system</th>\n",
       "      <th>bore</th>\n",
       "      <th>stroke</th>\n",
       "      <th>compression-ratio</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>peak-rpm</th>\n",
       "      <th>city-mpg</th>\n",
       "      <th>highway-mpg</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alfa-romero</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>two</td>\n",
       "      <td>convertible</td>\n",
       "      <td>rwd</td>\n",
       "      <td>front</td>\n",
       "      <td>88.6</td>\n",
       "      <td>168.8</td>\n",
       "      <td>64.1</td>\n",
       "      <td>...</td>\n",
       "      <td>130</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.47</td>\n",
       "      <td>2.68</td>\n",
       "      <td>9.0</td>\n",
       "      <td>111</td>\n",
       "      <td>5000</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>13495.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alfa-romero</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>two</td>\n",
       "      <td>convertible</td>\n",
       "      <td>rwd</td>\n",
       "      <td>front</td>\n",
       "      <td>88.6</td>\n",
       "      <td>168.8</td>\n",
       "      <td>64.1</td>\n",
       "      <td>...</td>\n",
       "      <td>130</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.47</td>\n",
       "      <td>2.68</td>\n",
       "      <td>9.0</td>\n",
       "      <td>111</td>\n",
       "      <td>5000</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>16500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alfa-romero</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>two</td>\n",
       "      <td>hatchback</td>\n",
       "      <td>rwd</td>\n",
       "      <td>front</td>\n",
       "      <td>94.5</td>\n",
       "      <td>171.2</td>\n",
       "      <td>65.5</td>\n",
       "      <td>...</td>\n",
       "      <td>152</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>2.68</td>\n",
       "      <td>3.47</td>\n",
       "      <td>9.0</td>\n",
       "      <td>154</td>\n",
       "      <td>5000</td>\n",
       "      <td>19</td>\n",
       "      <td>26</td>\n",
       "      <td>16500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>audi</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>four</td>\n",
       "      <td>sedan</td>\n",
       "      <td>fwd</td>\n",
       "      <td>front</td>\n",
       "      <td>99.8</td>\n",
       "      <td>176.6</td>\n",
       "      <td>66.2</td>\n",
       "      <td>...</td>\n",
       "      <td>109</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.40</td>\n",
       "      <td>10.0</td>\n",
       "      <td>102</td>\n",
       "      <td>5500</td>\n",
       "      <td>24</td>\n",
       "      <td>30</td>\n",
       "      <td>13950.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>audi</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>four</td>\n",
       "      <td>sedan</td>\n",
       "      <td>4wd</td>\n",
       "      <td>front</td>\n",
       "      <td>99.4</td>\n",
       "      <td>176.6</td>\n",
       "      <td>66.4</td>\n",
       "      <td>...</td>\n",
       "      <td>136</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.40</td>\n",
       "      <td>8.0</td>\n",
       "      <td>115</td>\n",
       "      <td>5500</td>\n",
       "      <td>18</td>\n",
       "      <td>22</td>\n",
       "      <td>17450.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          make fuel-type aspiration num-of-doors   body-style drive-wheels  \\\n",
       "0  alfa-romero       gas        std          two  convertible          rwd   \n",
       "1  alfa-romero       gas        std          two  convertible          rwd   \n",
       "2  alfa-romero       gas        std          two    hatchback          rwd   \n",
       "3         audi       gas        std         four        sedan          fwd   \n",
       "4         audi       gas        std         four        sedan          4wd   \n",
       "\n",
       "  engine-location  wheel-base  length  width  ...  engine-size  fuel-system  \\\n",
       "0           front        88.6   168.8   64.1  ...          130         mpfi   \n",
       "1           front        88.6   168.8   64.1  ...          130         mpfi   \n",
       "2           front        94.5   171.2   65.5  ...          152         mpfi   \n",
       "3           front        99.8   176.6   66.2  ...          109         mpfi   \n",
       "4           front        99.4   176.6   66.4  ...          136         mpfi   \n",
       "\n",
       "   bore stroke  compression-ratio horsepower  peak-rpm  city-mpg  highway-mpg  \\\n",
       "0  3.47   2.68                9.0        111      5000        21           27   \n",
       "1  3.47   2.68                9.0        111      5000        21           27   \n",
       "2  2.68   3.47                9.0        154      5000        19           26   \n",
       "3  3.19   3.40               10.0        102      5500        24           30   \n",
       "4  3.19   3.40                8.0        115      5500        18           22   \n",
       "\n",
       "     price  \n",
       "0  13495.0  \n",
       "1  16500.0  \n",
       "2  16500.0  \n",
       "3  13950.0  \n",
       "4  17450.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars = pd.read_csv('data/cars.csv')\n",
    "cars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Binarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0]], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binarizer = Binarizer(threshold = 25)\n",
    "highway_mgp_bin = binarizer.transform(cars[['highway-mpg']])\n",
    "highway_mgp_bin        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2** Using `FunctionTransformer`, transform the `city-mpg` and `highway-mpg` columns to a log-scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      3.044522\n",
       "1      3.044522\n",
       "2      2.944439\n",
       "3      3.178054\n",
       "4      2.890372\n",
       "         ...   \n",
       "188    3.135494\n",
       "189    2.944439\n",
       "190    2.890372\n",
       "191    3.258097\n",
       "192    2.944439\n",
       "Name: city-mpg, Length: 193, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func = FunctionTransformer(np.log)\n",
    "func.transform(cars['city-mpg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_log(x):\n",
    "    return np.log(x) + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most transformers you will use will require being *fit to training data* before using it. An example of this is one-hot-encoding: before applying one-hot encoding to a column, you must determine the number of distinct values in the column (as that number determines the number of columns in the output).\n",
    "\n",
    "**Question 3** *(Fit transformers properly handle unseen values)*\n",
    "\n",
    "1. One-hot encode the `body-style` column using `OneHotEncoder`. What is the dimension of the output? Which column corresponds to which value of `body-style`? (If you can't remember the attribute name, look up the documentation!)\n",
    "1. Fit a `OneHotEncoder` on the *first 5 rows* of the `body-style` column. Use this 'training data' to one-hot-encode the `body-style` in rest of the dataset. Why does it throw an exception? Look at the documentation -- what is the relevant parameter to avoid this? What are the implications of setting this parameter? What is the dimension of the output?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['convertible', 'hatchback', 'sedan', 'wagon', 'hardtop'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars['body-style'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = OneHotEncoder()\n",
    "enc.fit(cars[['body-style']].iloc[:5,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'auto'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(handle_unknown='ignore')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = OneHotEncoder(handle_unknown = 'ignore')\n",
    "enc.fit(cars[['body-style']].iloc[:5,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(handle_unknown='ignore')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.fit(cars[['body-style']].iloc[:5,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.transform(cars[['body-style']]).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you observed, the categories of `OneHotEncoder` are learned from training data and saved as an attribute of the transformer. These categories are then used to transform new, unseen data which is then used by other pieces of the ML pipeline.\n",
    "\n",
    "Below is an illustration of why *fitting* a transformer is so important:\n",
    "\n",
    "*The dangers of `pd.get_dummies`*: Pandas offers it's own one-hot encoder called `get_dummies`. This function is stateless; every time it's called, it determines the categories of the input data and one-hot encodes that data using those categories. However, as you saw in the above question, this is not a realistic use of the function!\n",
    "\n",
    "To illustrate this:\n",
    "1. We will create a one-hot encoding using scikit-learn that we will pass into a linear regression model.\n",
    "1. We will create a *stateless* one-hot encoder that we will pass into a linear regression model.\n",
    "\n",
    "Both of these models will be trained on the first 5 rows of the dataset; the rest will be used as 'unseen' data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = cars[['body-style']].head(5), cars['price'].head(5)\n",
    "X_test, y_test = cars[['body-style']].tail(-5), cars['price'].tail(-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using sklearn transformers. What are the categories of the OneHotEncoder?\n",
    "ohe = OneHotEncoder(handle_unknown='ignore')\n",
    "lr = LinearRegression()\n",
    "\n",
    "ohe.fit(X_train)\n",
    "features = ohe.transform(X_train)\n",
    "lr.fit(features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on the new data using the fit model:\n",
    "lr.predict(ohe.transform(X_test))[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using a stateless one-hot encoder.\n",
    "ohe = FunctionTransformer(pd.get_dummies, validate=False)\n",
    "lr = LinearRegression()\n",
    "\n",
    "ohe.fit(X_train)\n",
    "features = ohe.transform(X_train)\n",
    "lr.fit(features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug this!\n",
    "# lr.predict(ohe.transform(X_test))[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Even worse, there are cases where such an ML pipeline doesn't even throw an exception -- the incorrect columns get silently passed on. \n",
    "\n",
    "**The below predictions are wrong! Can you tell that it's wrong?** Debugging statistical output is notoriously hard -- this is why statistical analysis of the output data is always an important step to check your work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = cars[['body-style']].head(5), cars['price'].head(5)\n",
    "X_test, y_test = cars[['body-style']].iloc[5:20], cars['price'].iloc[5:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = FunctionTransformer(pd.get_dummies, validate=False)\n",
    "lr = LinearRegression()\n",
    "\n",
    "ohe.fit(X_train)\n",
    "features = ohe.transform(X_train)\n",
    "lr.fit(features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS IS WRONG! debug this! \n",
    "lr.predict(ohe.transform(X_test))[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building custom Transformers\n",
    "\n",
    "Building your own transformer class is easy! There is are convenient base-classes you can inherit: `TranformerMixin` and `BaseEstimator`. To subclass these classes, you need to:\n",
    "1. implement the `fit` method, and\n",
    "2. implement the `transform` method.\n",
    "Once you have done that, you can use your custom transformer as part of a `Pipeline` that can leverage all the nice features of scikit-learn (like feature-selection libraries and cross-validation).\n",
    "\n",
    "To get acquainted with the structure of a transformer, it's useful to look at `sklearn` source code. First, you will walk through the source code of the `Binarizer` transformer ([source code](https://github.com/scikit-learn/scikit-learn/blob/7813f7efb/sklearn/preprocessing/data.py#L1789)).\n",
    "\n",
    "The source code is included below. Note, that there is a lot of boiler-plate code, but the *transform* method is the relevant method. (Why does the fit method do nothing?)\n",
    "\n",
    "```\n",
    "class Binarizer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Binarize data (set feature values to 0 or 1) according to a threshold\n",
    "    Values greater than the threshold map to 1, while values less than\n",
    "    or equal to the threshold map to 0. With the default threshold of 0,\n",
    "    only positive values map to 1.\n",
    "    Binarization is a common operation on text count data where the\n",
    "    analyst can decide to only consider the presence or absence of a\n",
    "    feature rather than a quantified number of occurrences for instance.\n",
    "    It can also be used as a pre-processing step for estimators that\n",
    "    consider boolean random variables (e.g. modelled using the Bernoulli\n",
    "    distribution in a Bayesian setting).\n",
    "    Read more in the :ref:`User Guide <preprocessing_binarization>`.\n",
    "    Parameters\n",
    "    ----------\n",
    "    threshold : float, optional (0.0 by default)\n",
    "        Feature values below or equal to this are replaced by 0, above it by 1.\n",
    "        Threshold may not be less than 0 for operations on sparse matrices.\n",
    "    copy : boolean, optional, default True\n",
    "        set to False to perform inplace binarization and avoid a copy (if\n",
    "        the input is already a numpy array or a scipy.sparse CSR matrix).\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from sklearn.preprocessing import Binarizer\n",
    "    >>> X = [[ 1., -1.,  2.],\n",
    "    ...      [ 2.,  0.,  0.],\n",
    "    ...      [ 0.,  1., -1.]]\n",
    "    >>> transformer = Binarizer().fit(X)  # fit does nothing.\n",
    "    >>> transformer\n",
    "    Binarizer(copy=True, threshold=0.0)\n",
    "    >>> transformer.transform(X)\n",
    "    array([[1., 0., 1.],\n",
    "           [1., 0., 0.],\n",
    "           [0., 1., 0.]])\n",
    "    Notes\n",
    "    -----\n",
    "    If the input is a sparse matrix, only the non-zero values are subject\n",
    "    to update by the Binarizer class.\n",
    "    This estimator is stateless (besides constructor parameters), the\n",
    "    fit method does nothing but is useful when used in a pipeline.\n",
    "    See also\n",
    "    --------\n",
    "    binarize: Equivalent function without the estimator API.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, threshold=0.0, copy=True):\n",
    "        self.threshold = threshold\n",
    "        self.copy = copy\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"Do nothing and return the estimator unchanged\n",
    "        This method is just there to implement the usual API and hence\n",
    "        work in pipelines.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like\n",
    "        \"\"\"\n",
    "        check_array(X, accept_sparse='csr')\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, copy=None):\n",
    "        \"\"\"Binarize each element of X\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix}, shape [n_samples, n_features]\n",
    "            The data to binarize, element by element.\n",
    "            scipy.sparse matrices should be in CSR format to avoid an\n",
    "            un-necessary copy.\n",
    "        copy : bool\n",
    "            Copy the input X or not.\n",
    "        \"\"\"\n",
    "        copy = copy if copy is not None else self.copy\n",
    "        return binarize(X, threshold=self.threshold, copy=copy)\n",
    "\n",
    "    def _more_tags(self):\n",
    "        return {'stateless': True}\n",
    "```\n",
    "\n",
    "The relevant (portion of the) function `binarize` from the transform method is here:\n",
    "\n",
    "```\n",
    "def binarize(X, threshold=0.0, copy=True):\n",
    "    ...\n",
    "    cond = X > threshold\n",
    "    not_cond = np.logical_not(cond)\n",
    "    X[cond] = 1\n",
    "    X[not_cond] = 0\n",
    "    return X\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4** \n",
    "\n",
    "As a warm-up, create a transformer that drops the `i`th row of an input dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class ColumnDropper(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, index):\n",
    "        self.index = index\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Does nothing! Stateless!\n",
    "        \"\"\"\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Drops the ith column of X, where i=index\n",
    "        \"\"\"\n",
    "        \n",
    "        return np.delete(np.array(X), self.index, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['alfa-romero', 'gas', 'std', 'convertible'],\n",
       "       ['alfa-romero', 'gas', 'std', 'convertible'],\n",
       "       ['alfa-romero', 'gas', 'std', 'hatchback'],\n",
       "       ['audi', 'gas', 'std', 'sedan'],\n",
       "       ['audi', 'gas', 'std', 'sedan'],\n",
       "       ['audi', 'gas', 'std', 'sedan'],\n",
       "       ['audi', 'gas', 'std', 'sedan'],\n",
       "       ['audi', 'gas', 'std', 'wagon'],\n",
       "       ['audi', 'gas', 'turbo', 'sedan'],\n",
       "       ['bmw', 'gas', 'std', 'sedan'],\n",
       "       ['bmw', 'gas', 'std', 'sedan'],\n",
       "       ['bmw', 'gas', 'std', 'sedan'],\n",
       "       ['bmw', 'gas', 'std', 'sedan'],\n",
       "       ['bmw', 'gas', 'std', 'sedan'],\n",
       "       ['bmw', 'gas', 'std', 'sedan'],\n",
       "       ['bmw', 'gas', 'std', 'sedan'],\n",
       "       ['bmw', 'gas', 'std', 'sedan'],\n",
       "       ['chevrolet', 'gas', 'std', 'hatchback'],\n",
       "       ['chevrolet', 'gas', 'std', 'hatchback'],\n",
       "       ['chevrolet', 'gas', 'std', 'sedan'],\n",
       "       ['dodge', 'gas', 'std', 'hatchback'],\n",
       "       ['dodge', 'gas', 'std', 'hatchback'],\n",
       "       ['dodge', 'gas', 'turbo', 'hatchback'],\n",
       "       ['dodge', 'gas', 'std', 'hatchback'],\n",
       "       ['dodge', 'gas', 'std', 'sedan'],\n",
       "       ['dodge', 'gas', 'std', 'sedan'],\n",
       "       ['dodge', 'gas', 'std', 'wagon'],\n",
       "       ['dodge', 'gas', 'turbo', 'hatchback'],\n",
       "       ['honda', 'gas', 'std', 'hatchback'],\n",
       "       ['honda', 'gas', 'std', 'hatchback'],\n",
       "       ['honda', 'gas', 'std', 'hatchback'],\n",
       "       ['honda', 'gas', 'std', 'hatchback'],\n",
       "       ['honda', 'gas', 'std', 'hatchback'],\n",
       "       ['honda', 'gas', 'std', 'sedan'],\n",
       "       ['honda', 'gas', 'std', 'wagon'],\n",
       "       ['honda', 'gas', 'std', 'hatchback'],\n",
       "       ['honda', 'gas', 'std', 'hatchback'],\n",
       "       ['honda', 'gas', 'std', 'sedan'],\n",
       "       ['honda', 'gas', 'std', 'sedan'],\n",
       "       ['honda', 'gas', 'std', 'sedan'],\n",
       "       ['honda', 'gas', 'std', 'sedan'],\n",
       "       ['isuzu', 'gas', 'std', 'sedan'],\n",
       "       ['isuzu', 'gas', 'std', 'hatchback'],\n",
       "       ['jaguar', 'gas', 'std', 'sedan'],\n",
       "       ['jaguar', 'gas', 'std', 'sedan'],\n",
       "       ['jaguar', 'gas', 'std', 'sedan'],\n",
       "       ['mazda', 'gas', 'std', 'hatchback'],\n",
       "       ['mazda', 'gas', 'std', 'hatchback'],\n",
       "       ['mazda', 'gas', 'std', 'hatchback'],\n",
       "       ['mazda', 'gas', 'std', 'sedan'],\n",
       "       ['mazda', 'gas', 'std', 'sedan'],\n",
       "       ['mazda', 'gas', 'std', 'hatchback'],\n",
       "       ['mazda', 'gas', 'std', 'sedan'],\n",
       "       ['mazda', 'gas', 'std', 'hatchback'],\n",
       "       ['mazda', 'gas', 'std', 'sedan'],\n",
       "       ['mazda', 'gas', 'std', 'hatchback'],\n",
       "       ['mazda', 'gas', 'std', 'sedan'],\n",
       "       ['mazda', 'diesel', 'std', 'sedan'],\n",
       "       ['mercedes-benz', 'diesel', 'turbo', 'sedan'],\n",
       "       ['mercedes-benz', 'diesel', 'turbo', 'wagon'],\n",
       "       ['mercedes-benz', 'diesel', 'turbo', 'hardtop'],\n",
       "       ['mercedes-benz', 'diesel', 'turbo', 'sedan'],\n",
       "       ['mercedes-benz', 'gas', 'std', 'sedan'],\n",
       "       ['mercedes-benz', 'gas', 'std', 'convertible'],\n",
       "       ['mercedes-benz', 'gas', 'std', 'sedan'],\n",
       "       ['mercedes-benz', 'gas', 'std', 'hardtop'],\n",
       "       ['mercury', 'gas', 'turbo', 'hatchback'],\n",
       "       ['mitsubishi', 'gas', 'std', 'hatchback'],\n",
       "       ['mitsubishi', 'gas', 'std', 'hatchback'],\n",
       "       ['mitsubishi', 'gas', 'std', 'hatchback'],\n",
       "       ['mitsubishi', 'gas', 'turbo', 'hatchback'],\n",
       "       ['mitsubishi', 'gas', 'turbo', 'hatchback'],\n",
       "       ['mitsubishi', 'gas', 'std', 'hatchback'],\n",
       "       ['mitsubishi', 'gas', 'turbo', 'hatchback'],\n",
       "       ['mitsubishi', 'gas', 'turbo', 'hatchback'],\n",
       "       ['mitsubishi', 'gas', 'turbo', 'hatchback'],\n",
       "       ['mitsubishi', 'gas', 'std', 'sedan'],\n",
       "       ['mitsubishi', 'gas', 'std', 'sedan'],\n",
       "       ['mitsubishi', 'gas', 'turbo', 'sedan'],\n",
       "       ['mitsubishi', 'gas', 'std', 'sedan'],\n",
       "       ['nissan', 'gas', 'std', 'sedan'],\n",
       "       ['nissan', 'diesel', 'std', 'sedan'],\n",
       "       ['nissan', 'gas', 'std', 'sedan'],\n",
       "       ['nissan', 'gas', 'std', 'sedan'],\n",
       "       ['nissan', 'gas', 'std', 'wagon'],\n",
       "       ['nissan', 'gas', 'std', 'sedan'],\n",
       "       ['nissan', 'gas', 'std', 'hatchback'],\n",
       "       ['nissan', 'gas', 'std', 'sedan'],\n",
       "       ['nissan', 'gas', 'std', 'wagon'],\n",
       "       ['nissan', 'gas', 'std', 'hardtop'],\n",
       "       ['nissan', 'gas', 'std', 'hatchback'],\n",
       "       ['nissan', 'gas', 'std', 'sedan'],\n",
       "       ['nissan', 'gas', 'std', 'sedan'],\n",
       "       ['nissan', 'gas', 'std', 'wagon'],\n",
       "       ['nissan', 'gas', 'std', 'sedan'],\n",
       "       ['nissan', 'gas', 'std', 'hatchback'],\n",
       "       ['nissan', 'gas', 'turbo', 'hatchback'],\n",
       "       ['nissan', 'gas', 'std', 'hatchback'],\n",
       "       ['peugot', 'gas', 'std', 'sedan'],\n",
       "       ['peugot', 'diesel', 'turbo', 'sedan'],\n",
       "       ['peugot', 'gas', 'std', 'wagon'],\n",
       "       ['peugot', 'diesel', 'turbo', 'wagon'],\n",
       "       ['peugot', 'gas', 'std', 'sedan'],\n",
       "       ['peugot', 'diesel', 'turbo', 'sedan'],\n",
       "       ['peugot', 'gas', 'std', 'wagon'],\n",
       "       ['peugot', 'diesel', 'turbo', 'wagon'],\n",
       "       ['peugot', 'gas', 'std', 'sedan'],\n",
       "       ['peugot', 'diesel', 'turbo', 'sedan'],\n",
       "       ['peugot', 'gas', 'turbo', 'sedan'],\n",
       "       ['plymouth', 'gas', 'std', 'hatchback'],\n",
       "       ['plymouth', 'gas', 'turbo', 'hatchback'],\n",
       "       ['plymouth', 'gas', 'std', 'hatchback'],\n",
       "       ['plymouth', 'gas', 'std', 'sedan'],\n",
       "       ['plymouth', 'gas', 'std', 'sedan'],\n",
       "       ['plymouth', 'gas', 'std', 'wagon'],\n",
       "       ['plymouth', 'gas', 'turbo', 'hatchback'],\n",
       "       ['porsche', 'gas', 'std', 'hatchback'],\n",
       "       ['porsche', 'gas', 'std', 'hardtop'],\n",
       "       ['porsche', 'gas', 'std', 'hardtop'],\n",
       "       ['porsche', 'gas', 'std', 'convertible'],\n",
       "       ['saab', 'gas', 'std', 'hatchback'],\n",
       "       ['saab', 'gas', 'std', 'sedan'],\n",
       "       ['saab', 'gas', 'std', 'hatchback'],\n",
       "       ['saab', 'gas', 'std', 'sedan'],\n",
       "       ['saab', 'gas', 'turbo', 'hatchback'],\n",
       "       ['saab', 'gas', 'turbo', 'sedan'],\n",
       "       ['subaru', 'gas', 'std', 'hatchback'],\n",
       "       ['subaru', 'gas', 'std', 'hatchback'],\n",
       "       ['subaru', 'gas', 'std', 'hatchback'],\n",
       "       ['subaru', 'gas', 'std', 'sedan'],\n",
       "       ['subaru', 'gas', 'std', 'sedan'],\n",
       "       ['subaru', 'gas', 'std', 'sedan'],\n",
       "       ['subaru', 'gas', 'std', 'sedan'],\n",
       "       ['subaru', 'gas', 'turbo', 'sedan'],\n",
       "       ['subaru', 'gas', 'std', 'wagon'],\n",
       "       ['subaru', 'gas', 'std', 'wagon'],\n",
       "       ['subaru', 'gas', 'std', 'wagon'],\n",
       "       ['subaru', 'gas', 'turbo', 'wagon'],\n",
       "       ['toyota', 'gas', 'std', 'hatchback'],\n",
       "       ['toyota', 'gas', 'std', 'hatchback'],\n",
       "       ['toyota', 'gas', 'std', 'hatchback'],\n",
       "       ['toyota', 'gas', 'std', 'wagon'],\n",
       "       ['toyota', 'gas', 'std', 'wagon'],\n",
       "       ['toyota', 'gas', 'std', 'wagon'],\n",
       "       ['toyota', 'gas', 'std', 'sedan'],\n",
       "       ['toyota', 'gas', 'std', 'hatchback'],\n",
       "       ['toyota', 'diesel', 'std', 'sedan'],\n",
       "       ['toyota', 'diesel', 'std', 'hatchback'],\n",
       "       ['toyota', 'gas', 'std', 'sedan'],\n",
       "       ['toyota', 'gas', 'std', 'hatchback'],\n",
       "       ['toyota', 'gas', 'std', 'sedan'],\n",
       "       ['toyota', 'gas', 'std', 'sedan'],\n",
       "       ['toyota', 'gas', 'std', 'hatchback'],\n",
       "       ['toyota', 'gas', 'std', 'sedan'],\n",
       "       ['toyota', 'gas', 'std', 'hatchback'],\n",
       "       ['toyota', 'gas', 'std', 'hardtop'],\n",
       "       ['toyota', 'gas', 'std', 'hardtop'],\n",
       "       ['toyota', 'gas', 'std', 'hatchback'],\n",
       "       ['toyota', 'gas', 'std', 'hardtop'],\n",
       "       ['toyota', 'gas', 'std', 'hatchback'],\n",
       "       ['toyota', 'gas', 'std', 'convertible'],\n",
       "       ['toyota', 'gas', 'std', 'sedan'],\n",
       "       ['toyota', 'diesel', 'turbo', 'sedan'],\n",
       "       ['toyota', 'gas', 'std', 'hatchback'],\n",
       "       ['toyota', 'gas', 'std', 'sedan'],\n",
       "       ['toyota', 'gas', 'std', 'hatchback'],\n",
       "       ['toyota', 'gas', 'std', 'hatchback'],\n",
       "       ['toyota', 'gas', 'std', 'hatchback'],\n",
       "       ['toyota', 'gas', 'std', 'sedan'],\n",
       "       ['toyota', 'gas', 'std', 'wagon'],\n",
       "       ['volkswagen', 'diesel', 'std', 'sedan'],\n",
       "       ['volkswagen', 'gas', 'std', 'sedan'],\n",
       "       ['volkswagen', 'diesel', 'std', 'sedan'],\n",
       "       ['volkswagen', 'gas', 'std', 'sedan'],\n",
       "       ['volkswagen', 'gas', 'std', 'sedan'],\n",
       "       ['volkswagen', 'diesel', 'turbo', 'sedan'],\n",
       "       ['volkswagen', 'gas', 'std', 'sedan'],\n",
       "       ['volkswagen', 'gas', 'std', 'convertible'],\n",
       "       ['volkswagen', 'gas', 'std', 'hatchback'],\n",
       "       ['volkswagen', 'gas', 'std', 'sedan'],\n",
       "       ['volkswagen', 'diesel', 'turbo', 'sedan'],\n",
       "       ['volkswagen', 'gas', 'std', 'wagon'],\n",
       "       ['volvo', 'gas', 'std', 'sedan'],\n",
       "       ['volvo', 'gas', 'std', 'wagon'],\n",
       "       ['volvo', 'gas', 'std', 'sedan'],\n",
       "       ['volvo', 'gas', 'std', 'wagon'],\n",
       "       ['volvo', 'gas', 'turbo', 'sedan'],\n",
       "       ['volvo', 'gas', 'turbo', 'wagon'],\n",
       "       ['volvo', 'gas', 'std', 'sedan'],\n",
       "       ['volvo', 'gas', 'turbo', 'sedan'],\n",
       "       ['volvo', 'gas', 'std', 'sedan'],\n",
       "       ['volvo', 'diesel', 'turbo', 'sedan'],\n",
       "       ['volvo', 'gas', 'turbo', 'sedan']], dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cd = ColumnDropper(index=3)\n",
    "cd.transform(cars.iloc[:,:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5**\n",
    "\n",
    "Columns that don't have much variation are not very useful for prediction. An extreme case is when a column has only a single value.  Create a \"feature selection\" transformer that drops any columns that don't have a standard-deviation greater than an input threshold.\n",
    "\n",
    "* What needs to be calculated during the fitting process? When is the standard deviation calculated?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lvd = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LowStdColumnDropper' object has no attribute 'transform'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m----------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-fb4062a1478b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mlvd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLowStdColumnDropper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthresh\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mlvd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcars\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect_dtypes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'number'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlvd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcars\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect_dtypes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'number'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'LowStdColumnDropper' object has no attribute 'transform'"
     ]
    }
   ],
   "source": [
    "lvd = LowStdColumnDropper(thresh=10)\n",
    "lvd.fit(cars.select_dtypes('number'))\n",
    "out = lvd.transform(cars.select_dtypes('number'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = LowStdColumnDropper(thresh=10)\n",
    "out.fit_transform(cars.select_dtypes('number')).shape[0] == cars.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Boolean index has wrong length: 14 instead of 24",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m----------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-523a892f9bd8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mcars\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mE:\\Workspace\\DSC 80\\di\\09-sklearn\\assignment\\discussion.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    697\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m             \u001b[1;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    700\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Workspace\\DSC 80\\di\\09-sklearn\\assignment\\discussion.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     32\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mout\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[1;33m...\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    887\u001b[0m                     \u001b[1;31m# AttributeError for IntervalTree get_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtakeable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_takeable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m             \u001b[1;31m# we by definition only have the 0th axis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1452\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_lowerdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1453\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1454\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_tuple_same_dim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1456\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_list_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple_same_dim\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m    773\u001b[0m                 \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    774\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 775\u001b[1;33m             \u001b[0mretval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mretval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    776\u001b[0m             \u001b[1;31m# We should never have retval.ndim < self.ndim, as that should\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    777\u001b[0m             \u001b[1;31m#  be handled by the _getitem_lowerdim call above.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1486\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_bool_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1487\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1488\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getbool_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1489\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1490\u001b[0m         \u001b[1;31m# a list of integers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getbool_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m    910\u001b[0m         \u001b[1;31m# caller is responsible for ensuring non-None axis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    911\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 912\u001b[1;33m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_bool_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    913\u001b[0m         \u001b[0minds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_take_with_is_copy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36mcheck_bool_indexer\u001b[1;34m(index, key)\u001b[0m\n\u001b[0;32m   2280\u001b[0m         \u001b[1;31m# key may contain nan elements, check_array_indexer needs bool array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2281\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2282\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcheck_array_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2283\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2284\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda\\lib\\site-packages\\pandas\\core\\indexers.py\u001b[0m in \u001b[0;36mcheck_array_indexer\u001b[1;34m(array, indexer)\u001b[0m\n\u001b[0;32m    483\u001b[0m         \u001b[1;31m# GH26658\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 485\u001b[1;33m             raise IndexError(\n\u001b[0m\u001b[0;32m    486\u001b[0m                 \u001b[1;34mf\"Boolean index has wrong length: \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    487\u001b[0m                 \u001b[1;34mf\"{len(indexer)} instead of {len(array)}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: Boolean index has wrong length: 14 instead of 24"
     ]
    }
   ],
   "source": [
    "out.fit_transform(cars).shape[0] == cars.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "deletable": false,
    "editable": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong style='color: red;'><pre style='display: inline;'>q5</pre> results:</strong></p><p><strong><pre style='display: inline;'>q5 - 1</pre> result:</strong></p><pre>    Test case passed!</pre><p><strong><pre style='display: inline;'>q5 - 2</pre> result:</strong></p><pre>    Trying:\n",
       "        out.fit_transform(cars).shape[0] == cars.shape[0]\n",
       "    Expecting:\n",
       "        True\n",
       "    **********************************************************************\n",
       "    Line 1, in q5 1\n",
       "    Failed example:\n",
       "        out.fit_transform(cars).shape[0] == cars.shape[0]\n",
       "    Exception raised:\n",
       "        Traceback (most recent call last):\n",
       "          File \"E:\\anaconda\\lib\\doctest.py\", line 1336, in __run\n",
       "            exec(compile(example.source, filename, \"single\",\n",
       "          File \"<doctest q5 1[0]>\", line 1, in <module>\n",
       "            out.fit_transform(cars).shape[0] == cars.shape[0]\n",
       "          File \"E:\\anaconda\\lib\\site-packages\\pandas\\core\\generic.py\", line 5465, in __getattr__\n",
       "            return object.__getattribute__(self, name)\n",
       "        AttributeError: 'DataFrame' object has no attribute 'fit_transform'\n",
       "</pre><p><strong><pre style='display: inline;'>q5 - 2</pre> message:</strong> doctest 1</p><p><strong><pre style='display: inline;'>q5 - 3</pre> result:</strong></p><pre>    Trying:\n",
       "        out.fit_transform(cars).shape[1] <= cars.shape[1]\n",
       "    Expecting:\n",
       "        True\n",
       "    **********************************************************************\n",
       "    Line 1, in q5 2\n",
       "    Failed example:\n",
       "        out.fit_transform(cars).shape[1] <= cars.shape[1]\n",
       "    Exception raised:\n",
       "        Traceback (most recent call last):\n",
       "          File \"E:\\anaconda\\lib\\doctest.py\", line 1336, in __run\n",
       "            exec(compile(example.source, filename, \"single\",\n",
       "          File \"<doctest q5 2[0]>\", line 1, in <module>\n",
       "            out.fit_transform(cars).shape[1] <= cars.shape[1]\n",
       "          File \"E:\\anaconda\\lib\\site-packages\\pandas\\core\\generic.py\", line 5465, in __getattr__\n",
       "            return object.__getattribute__(self, name)\n",
       "        AttributeError: 'DataFrame' object has no attribute 'fit_transform'\n",
       "</pre><p><strong><pre style='display: inline;'>q5 - 3</pre> message:</strong> doctest 2</p><p><strong><pre style='display: inline;'>q5 - 4</pre> result:</strong></p><pre>    Trying:\n",
       "        out.fit_transform(cars).shape[1] == 14\n",
       "    Expecting:\n",
       "        True\n",
       "    **********************************************************************\n",
       "    Line 1, in q5 3\n",
       "    Failed example:\n",
       "        out.fit_transform(cars).shape[1] == 14\n",
       "    Exception raised:\n",
       "        Traceback (most recent call last):\n",
       "          File \"E:\\anaconda\\lib\\doctest.py\", line 1336, in __run\n",
       "            exec(compile(example.source, filename, \"single\",\n",
       "          File \"<doctest q5 3[0]>\", line 1, in <module>\n",
       "            out.fit_transform(cars).shape[1] == 14\n",
       "          File \"E:\\anaconda\\lib\\site-packages\\pandas\\core\\generic.py\", line 5465, in __getattr__\n",
       "            return object.__getattribute__(self, name)\n",
       "        AttributeError: 'DataFrame' object has no attribute 'fit_transform'\n",
       "</pre><p><strong><pre style='display: inline;'>q5 - 4</pre> message:</strong> correct number of columns dropped for thresh=0.25</p><p><strong><pre style='display: inline;'>q5 - 5</pre> result:</strong></p><pre>    Trying:\n",
       "        out1.fit_transform(cars).shape[1] == 12\n",
       "    Expecting:\n",
       "        True\n",
       "    **********************************************************************\n",
       "    Line 1, in q5 4\n",
       "    Failed example:\n",
       "        out1.fit_transform(cars).shape[1] == 12\n",
       "    Exception raised:\n",
       "        Traceback (most recent call last):\n",
       "          File \"E:\\anaconda\\lib\\doctest.py\", line 1336, in __run\n",
       "            exec(compile(example.source, filename, \"single\",\n",
       "          File \"<doctest q5 4[0]>\", line 1, in <module>\n",
       "            out1.fit_transform(cars).shape[1] == 12\n",
       "        NameError: name 'out1' is not defined\n",
       "</pre><p><strong><pre style='display: inline;'>q5 - 5</pre> message:</strong> correct number of columns dropped for thresh=1.0</p><p><strong><pre style='display: inline;'>q5 - 6</pre> result:</strong></p><pre>    Trying:\n",
       "        out2.fit_transform(cars).shape[1] == 6\n",
       "    Expecting:\n",
       "        True\n",
       "    **********************************************************************\n",
       "    Line 1, in q5 5\n",
       "    Failed example:\n",
       "        out2.fit_transform(cars).shape[1] == 6\n",
       "    Exception raised:\n",
       "        Traceback (most recent call last):\n",
       "          File \"E:\\anaconda\\lib\\doctest.py\", line 1336, in __run\n",
       "            exec(compile(example.source, filename, \"single\",\n",
       "          File \"<doctest q5 5[0]>\", line 1, in <module>\n",
       "            out2.fit_transform(cars).shape[1] == 6\n",
       "        NameError: name 'out2' is not defined\n",
       "</pre><p><strong><pre style='display: inline;'>q5 - 6</pre> message:</strong> correct number of columns dropped for thresh=10.0</p>"
      ],
      "text/plain": [
       "q5 results:\n",
       "    q5 - 1 result:\n",
       "        Test case passed!\n",
       "\n",
       "    q5 - 2 result:\n",
       "        Trying:\n",
       "            out.fit_transform(cars).shape[0] == cars.shape[0]\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 1, in q5 1\n",
       "        Failed example:\n",
       "            out.fit_transform(cars).shape[0] == cars.shape[0]\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"E:\\anaconda\\lib\\doctest.py\", line 1336, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q5 1[0]>\", line 1, in <module>\n",
       "                out.fit_transform(cars).shape[0] == cars.shape[0]\n",
       "              File \"E:\\anaconda\\lib\\site-packages\\pandas\\core\\generic.py\", line 5465, in __getattr__\n",
       "                return object.__getattribute__(self, name)\n",
       "            AttributeError: 'DataFrame' object has no attribute 'fit_transform'\n",
       "\n",
       "    q5 - 2 message: doctest 1\n",
       "\n",
       "    q5 - 3 result:\n",
       "        Trying:\n",
       "            out.fit_transform(cars).shape[1] <= cars.shape[1]\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 1, in q5 2\n",
       "        Failed example:\n",
       "            out.fit_transform(cars).shape[1] <= cars.shape[1]\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"E:\\anaconda\\lib\\doctest.py\", line 1336, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q5 2[0]>\", line 1, in <module>\n",
       "                out.fit_transform(cars).shape[1] <= cars.shape[1]\n",
       "              File \"E:\\anaconda\\lib\\site-packages\\pandas\\core\\generic.py\", line 5465, in __getattr__\n",
       "                return object.__getattribute__(self, name)\n",
       "            AttributeError: 'DataFrame' object has no attribute 'fit_transform'\n",
       "\n",
       "    q5 - 3 message: doctest 2\n",
       "\n",
       "    q5 - 4 result:\n",
       "        Trying:\n",
       "            out.fit_transform(cars).shape[1] == 14\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 1, in q5 3\n",
       "        Failed example:\n",
       "            out.fit_transform(cars).shape[1] == 14\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"E:\\anaconda\\lib\\doctest.py\", line 1336, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q5 3[0]>\", line 1, in <module>\n",
       "                out.fit_transform(cars).shape[1] == 14\n",
       "              File \"E:\\anaconda\\lib\\site-packages\\pandas\\core\\generic.py\", line 5465, in __getattr__\n",
       "                return object.__getattribute__(self, name)\n",
       "            AttributeError: 'DataFrame' object has no attribute 'fit_transform'\n",
       "\n",
       "    q5 - 4 message: correct number of columns dropped for thresh=0.25\n",
       "\n",
       "    q5 - 5 result:\n",
       "        Trying:\n",
       "            out1.fit_transform(cars).shape[1] == 12\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 1, in q5 4\n",
       "        Failed example:\n",
       "            out1.fit_transform(cars).shape[1] == 12\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"E:\\anaconda\\lib\\doctest.py\", line 1336, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q5 4[0]>\", line 1, in <module>\n",
       "                out1.fit_transform(cars).shape[1] == 12\n",
       "            NameError: name 'out1' is not defined\n",
       "\n",
       "    q5 - 5 message: correct number of columns dropped for thresh=1.0\n",
       "\n",
       "    q5 - 6 result:\n",
       "        Trying:\n",
       "            out2.fit_transform(cars).shape[1] == 6\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 1, in q5 5\n",
       "        Failed example:\n",
       "            out2.fit_transform(cars).shape[1] == 6\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"E:\\anaconda\\lib\\doctest.py\", line 1336, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q5 5[0]>\", line 1, in <module>\n",
       "                out2.fit_transform(cars).shape[1] == 6\n",
       "            NameError: name 'out2' is not defined\n",
       "\n",
       "    q5 - 6 message: correct number of columns dropped for thresh=10.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-Learn Pipelines\n",
    "\n",
    "Pipelines are ways of chaining transformers and estimators together. \n",
    "* A **Pipeline** object is a sequence of transformers that perhaps end with estimator.\n",
    "* When you call `.fit(X, y)` on a pipeline, the pipeline calls `fit_transform` on each successive transformer in the pipeline, passing the transformed data to the next transformer in the sequence.\n",
    "* A pipeline that consists of a sequence of transformers is itself a transformer.\n",
    "* A pipeline that consists of a sequence of transformers, followed by an estimator, is itself an estimator.\n",
    "    - These observations allow you put pipelines inside of other pipelines!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 6** Create a *single* pipeline that consists of a `OneHotEncoder`, followed by a `LowStdColumnDropper`, followed by a `LinearRegression` model. That is, one-hot encode the categorical features, drop the low-variance columns, and use those features to fit a linear regression model. Your threshold for \"small standard deviation\" should be `0.1`. \n",
    "\n",
    "*Remark:* Be sure to pass `sparse=False` into `OneHotEncoder` (or else, make your `LowStdColumnDropper` handle sparse matrices).\n",
    "\n",
    "How many columns did your pipeline drop? (Use the `named_steps` attribute!)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting columns together using `ColumnTransformer`\n",
    "\n",
    "You can run many different transformers in parallel on different subsets of columns using `ColumnTransformer` (see the [docs](https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html#sklearn.compose.ColumnTransformer)).\n",
    "\n",
    "One common pattern for using `ColumnTransformer` is to create a transformer pipeline for each kind of data in your dataset and use `ColumnTransformer` to put the transformed features together into a single dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 7**\n",
    "\n",
    "Create a general pipeline that transforms different data-kinds with appropriate generic features (e.g. one-hot-encoder, ordinal-encoder) by filling in the `...` below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantitative_cols = ...\n",
    "ordinal_cols = ...\n",
    "nominal_cols = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quantitative_pipeline = Pipeline([...])\n",
    "# ordinal_pipeline = Pipeline([...])\n",
    "# nominal_pipeline = Pipeline([...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_eng_pipeline = ColumnTransformer([\n",
    "#     ('quant', quantitative_pipeline, quantitative_cols),\n",
    "#     ('ordin', ordinal_pipeline, ordinal_cols),\n",
    "#     ('nomin', nominal_pipeline, nominal_cols)\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pl = Pipeline([feature_eng_pipeline, LinearRegression()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 8** \n",
    "\n",
    "Fit the pipeline and predict with it. Check the outputs at each step using `named_steps`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finished? Turn in Question 5 for Grading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations! You're done!\n",
    "\n",
    "* Submit your `.py` file to Gradescope. Note that you only need to submit the `.py` file; this notebook should not be uploaded. Make sure that all of your work is in the `.py` file and not here by running the doctests: `python -m doctest discussion.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "otter": {
   "tests": {
    "q5": {
     "name": "q5",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> import doctest\n>>> doctest.run_docstring_examples(LowStdColumnDropper.transform, {'LowStdColumnDropper.transform': LowStdColumnDropper.transform,\n...                                                               'LowStdColumnDropper': LowStdColumnDropper,\n...                                                               'pd': pd})\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> out.fit_transform(cars).shape[0] == cars.shape[0]\nTrue",
         "failure_message": "doctest 1",
         "hidden": false,
         "locked": false,
         "points": 2
        },
        {
         "code": ">>> out.fit_transform(cars).shape[1] <= cars.shape[1]\nTrue",
         "failure_message": "doctest 2",
         "hidden": false,
         "locked": false,
         "points": 2
        },
        {
         "code": ">>> out.fit_transform(cars).shape[1] == 14\nTrue",
         "failure_message": "correct number of columns dropped for thresh=0.25",
         "hidden": false,
         "locked": false,
         "points": 2
        },
        {
         "code": ">>> out1.fit_transform(cars).shape[1] == 12\nTrue",
         "failure_message": "correct number of columns dropped for thresh=1.0",
         "hidden": false,
         "locked": false,
         "points": 2
        },
        {
         "code": ">>> out2.fit_transform(cars).shape[1] == 6\nTrue",
         "failure_message": "correct number of columns dropped for thresh=10.0",
         "hidden": false,
         "locked": false,
         "points": 2
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
